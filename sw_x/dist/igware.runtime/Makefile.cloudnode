# -*-Makefile-*-
export PRODUCT=cloudnode

# makefile included by all sw_x/dist/igware.runtime makefiles
include igware.runtime.common.mk
# makefile included by all sw_x/dist/* makefiles
include $(WORKDIR)/sw_x/dist/Makefile.common


# --- this target should clean the machine before building the product
.PHONY: clean
clean:
	rm -fr $(BUILDROOT)/*/$(PRODUCT)

bump_build_number:
	# get lock
	ssh $(LOCK_USER)@$(LOCK_MASTER) "$(LOCK_SCRIPT) -a get -n build_number.$(BRANCH_NAME) -t exclusive -r $(PRODUCT)"
	# get the latest version of the file
	svn update $(BUILD_NUMBER_FILE)
	# increment the build number
	echo $(shell echo $$(( $(BUILD_NUMBER) + 1 )) ) > $(BUILD_NUMBER_FILE)
	# check the change in
	svn ci -m 'bump $(PRODUCT) build number' $(BUILD_NUMBER_FILE)
	# release lock
	ssh $(LOCK_USER)@$(LOCK_MASTER) "$(LOCK_SCRIPT) -a release -n build_number.$(BRANCH_NAME) -t exclusive -r $(PRODUCT)"

# --- this target should install any tools needed to build the product
.PHONY: build_tools
build_tools: bump_build_number

# --- this target should build the product
.PHONY: default
default:
	mkdir -p $(TMPDIR)
	make -C $(WORKDIR)/sw_x default
	make -C $(WORKDIR)/sw_x libccd_client-shr
	make DEBUG=1 -C $(WORKDIR)/sw_x gvm_core/daemons/ccd/ccd_cloudnode

export LOCAL_SAVE_DIR = /tmp

export TMPDIR = $(LOCAL_SAVE_DIR)/ccd_cloudnode
export SAVE_TGZ = ccd_cloudnode.$(BUILD_DATE).$(BUILD_VERSION).tar.gz
export LNK_NAME = ccd_cloudnode.tar.gz
export REMOTE_SAVE_DIR = $(PRODUCT_STORAGE_DIR)/ccd_cloudnode

export SAVE_TGZ2 = CloudNodeClientSDK.$(BUILD_DATE).$(BUILD_VERSION).tar.gz
export LNK_NAME2 = CloudNodeClientSDK.tar.gz
export REMOTE_SAVE_DIR2 = $(PRODUCT_STORAGE_DIR)/CloudNodeClientSDK

export DXSHELL_TMPDIR = $(LOCAL_SAVE_DIR)/dxshell_cloudnode
export DXSHELL_SAVE_TGZ = dxshell_cloudnode.$(BUILD_DATE).$(BUILD_VERSION).tar.gz
export DXSHELL_LNK_NAME = dxshell_cloudnode.tar.gz
export DXSHELL_REMOTE_SAVE_DIR = $(PRODUCT_STORAGE_DIR)/dxshell_cloudnode

export TESTS_TGZ = tests_cloudnode.$(BUILD_DATE).$(BUILD_VERSION).tar.gz
export TESTS_LNK_NAME = tests_cloudnode.tar.gz
export TESTS_REMOTE_SAVE_DIR = $(PRODUCT_STORAGE_DIR)/tests_cloudnode
export BUILDROOT_TEST_FILES = release/$(PRODUCT)/gvm_core/internal/vssts/tests/vs_psn/vs_psn \
                              release/$(PRODUCT)/gvm_core/internal/vssts/tests/vs_psn/vsTest_dbeh.sh \
                              release/$(PRODUCT)/gvm_core/vpl/tests/vplTest \
                              release/$(PRODUCT)/gvm_core/vplex/tests/vplexTest \
                              release/$(PRODUCT)/gvm_apps/repair_tool/repair_tool \
                              release/$(PRODUCT)/storageNode/datasetdb2/tests/TestDatasetDB \
                              release/$(PRODUCT)/gvm_core/internal/vssi/tests/stream/vsStreamTest \
                              release/$(PRODUCT)/tests/ccd/test_sync/test_ccd_sync \
                              release/$(PRODUCT)/es_core/kernel/test_decrypt_content \
                              release/$(PRODUCT)/es_core/kernel/test_decrypt_secret_cred \
                              release/$(PRODUCT)/gvm_core/internal/simple_http/tests/test_parse_query_string \
                              release/$(PRODUCT)/tests/sync_config/syncConfig/syncConfigTest

# --- this target should archive any build outputs off to a different system
.PHONY: dist
dist:
	# Save off ccd_cloudnode
	-rm -rf $(TMPDIR)
	mkdir $(TMPDIR)
	cp $(BUILDROOT)/release/$(PRODUCT)/gvm_core/daemons/ccd/ccd_cloudnode $(TMPDIR)
	cp $(BUILDROOT)/release/$(PRODUCT)/gvm_core/daemons/ccd/ccd_cloudnode.debug $(TMPDIR)
	cp $(BUILDROOT)/debug/$(PRODUCT)/gvm_core/daemons/ccd/ccd_cloudnode $(TMPDIR)/ccd_cloudnode.debug_build
	cp $(BUILDROOT)/release/$(PRODUCT)/gvm_apps/actool/platform_linux/actool_app $(TMPDIR)
	cp $(WORKDIR)/sw_x/gvm_core/conf/ccd.conf.tmpl $(TMPDIR)
	cd $(TMPDIR) && tar czvf $(LOCAL_SAVE_DIR)/$(SAVE_TGZ) *
	ssh $(STORE_USER)@$(STORE_HOST) "mkdir -p $(REMOTE_SAVE_DIR)"
	scp $(LOCAL_SAVE_DIR)/$(SAVE_TGZ) $(STORE_USER)@$(STORE_HOST):$(REMOTE_SAVE_DIR)/$(SAVE_TGZ)
	ssh $(STORE_USER)@$(STORE_HOST) "cd $(REMOTE_SAVE_DIR) && rm -f $(LNK_NAME) && ln -s $(SAVE_TGZ) $(LNK_NAME)"
	rm -f $(LOCAL_SAVE_DIR)/$(SAVE_TGZ)

	# tar up the dxshell and save it off.
	-rm -rf $(DXSHELL_TMPDIR)
	mkdir -p $(DXSHELL_TMPDIR)
	cp $(BUILDROOT)/release/$(PRODUCT)/tests/dxshell/dxshell_cloudnode $(DXSHELL_TMPDIR)
	cp $(BUILDROOT)/release/$(PRODUCT)/tests/dxshell/dxshell_cloudnode.debug $(DXSHELL_TMPDIR)
	cp $(BUILDROOT)/release/$(PRODUCT)/gvm_core/daemons/ccd/ccd_cloudnode  $(DXSHELL_TMPDIR)
	cp $(BUILDROOT)/release/$(PRODUCT)/gvm_core/daemons/ccd/ccd_cloudnode.debug  $(DXSHELL_TMPDIR)
	cp $(BUILDROOT)/debug/$(PRODUCT)/gvm_core/daemons/ccd/ccd_cloudnode  $(DXSHELL_TMPDIR)/ccd_cloudnode.debug_build
	cp $(BUILDROOT)/release/$(PRODUCT)/gvm_core/daemons/ccd/ccd $(DXSHELL_TMPDIR)
	cp $(BUILDROOT)/release/$(PRODUCT)/gvm_core/daemons/ccd/ccd.debug $(DXSHELL_TMPDIR)
	cp $(BUILDROOT)/release/$(PRODUCT)/gvm_apps/dx_remote_agent/platform_linux/dx_remote_agent_cloudnode $(DXSHELL_TMPDIR)
	cp $(BUILDROOT)/release/$(PRODUCT)/gvm_apps/imltool/imltool $(DXSHELL_TMPDIR)
	cp $(WORKDIR)/sw_x/tests/dxshell/checkStreamMultirangeResult_ref.out $(DXSHELL_TMPDIR)
	cp $(WORKDIR)/sw_x/tests/dxshell/test.jpg $(DXSHELL_TMPDIR)
	cp $(WORKDIR)/sw_x/tests/dxshell/test_thumb.jpg $(DXSHELL_TMPDIR)
	cp $(WORKDIR)/sw_x/gvm_core/conf/ccd.conf.tmpl $(DXSHELL_TMPDIR)
	cd $(DXSHELL_TMPDIR) && wget http://$(STORE_HOST):$(HTTP_PORT)/$(ARCHIVED_TESTDATADIR)/$(DXSHELL_INCLUDE_FILES)
	cd $(DXSHELL_TMPDIR) && tar xvzf $(DXSHELL_INCLUDE_FILES) && rm -f $(DXSHELL_INCLUDE_FILES)
	cd $(DXSHELL_TMPDIR) && tar czvf $(LOCAL_SAVE_DIR)/$(DXSHELL_SAVE_TGZ) *
	ssh $(STORE_USER)@$(STORE_HOST) "mkdir -p $(DXSHELL_REMOTE_SAVE_DIR)"
	scp $(LOCAL_SAVE_DIR)/$(DXSHELL_SAVE_TGZ)  $(STORE_USER)@$(STORE_HOST):$(DXSHELL_REMOTE_SAVE_DIR)/$(DXSHELL_SAVE_TGZ)
	ssh $(STORE_USER)@$(STORE_HOST) "cd $(DXSHELL_REMOTE_SAVE_DIR) && rm -f $(DXSHELL_LNK_NAME) && ln -s $(DXSHELL_SAVE_TGZ) $(DXSHELL_LNK_NAME)"
	rm -f $(LOCAL_SAVE_DIR)/$(DXSHELL_SAVE_TGZ)

	# tar up tests and copy to distribution location
	cd $(BUILDROOT) && tar czvf $(LOCAL_SAVE_DIR)/$(TESTS_TGZ) $(BUILDROOT_TEST_FILES)
	ssh $(STORE_USER)@$(STORE_HOST) "mkdir -p $(TESTS_REMOTE_SAVE_DIR)"
	scp $(LOCAL_SAVE_DIR)/$(TESTS_TGZ) $(STORE_USER)@$(STORE_HOST):$(TESTS_REMOTE_SAVE_DIR)/$(TESTS_TGZ)
	ssh $(STORE_USER)@$(STORE_HOST) "cd $(TESTS_REMOTE_SAVE_DIR) && rm -f $(TESTS_LNK_NAME) && ln -s $(TESTS_TGZ) $(TESTS_LNK_NAME)"
	rm -f $(LOCAL_SAVE_DIR)/$(TESTS_TGZ)

	# tar up the CloudNode Client SDK and save it off.
	cp $(BUILDROOT)/release/$(PRODUCT)/gvm_core/daemons/ccd/libccd_client-shr.so \
		$(BUILDROOT)/release/$(PRODUCT)/gvm_core/daemons/ccd/sdk/lib/
	cd $(BUILDROOT)/release/$(PRODUCT)/gvm_core/daemons/ccd/sdk && \
		tar czvf $(LOCAL_SAVE_DIR)/$(SAVE_TGZ2) *
	ssh $(STORE_USER)@$(STORE_HOST) "mkdir -p $(REMOTE_SAVE_DIR2)"
	scp $(LOCAL_SAVE_DIR)/$(SAVE_TGZ2) $(STORE_USER)@$(STORE_HOST):$(REMOTE_SAVE_DIR2)/$(SAVE_TGZ2)
	ssh $(STORE_USER)@$(STORE_HOST) "cd $(REMOTE_SAVE_DIR2) && rm -f $(LNK_NAME2) && ln -s $(SAVE_TGZ2) $(LNK_NAME2)"
	rm -f $(LOCAL_SAVE_DIR)/$(SAVE_TGZ2)

.PHONY: printenv
printenv:
	env
	pwd

# --- this target should clean the machine before running tests
.PHONY: clean_tests
clean_tests:

# --- this target should install anything needed to test the product
# --- assume that the build of the product and test of the product DO NOT occur on the same machine
.PHONY: install_tests
install_tests: get_idt_tool

.PHONY: get_idt_tool
get_idt_tool:
	mkdir -p $(WORKDIR)/sw_i/tools
	scp $(STORE_USER)@$(STORE_HOST):$(FS_PC_INFRA_STORE_PATH)/idt/idt.zip $(WORKDIR)/sw_i/tools
	cd $(WORKDIR)/sw_i/tools && unzip idt.zip

# --- this target should execute the tests (usually using the testharness)
.PHONY: run_tests
run_tests:
	$(WORKDIR)/sw_x/dist/igware.runtime/make_validated_links.sh -a save -u $(STORE_USER) -n $(STORE_HOST) -d $(PRODUCT_STORAGE_DIR) -s ccd_cloudnode -s CloudNodeClientSDK -s dxshell_cloudnode
	$(WORKDIR)/sw_x/tools/testharness/bin/testharness.py -c $(WORKDIR)/sw_x/tools/testharness/conf/runs/buildbot_tests.$(PRODUCT).$(LAB).run -o /tmp/testharness/output_$(PRODUCT)/$(BUILD_DATE) -b $(STORE_USER)@$(STORE_HOST):/$(FS_STORE_TEST_PATH)/$(BRANCH_NAME)/$(BUILD_DATE)_$(PRODUCT)_$(LAB) -k
	# since the tests have passed, create the links indicating the build has been validated
	$(WORKDIR)/sw_x/dist/igware.runtime/make_validated_links.sh -a link -u $(STORE_USER) -n $(STORE_HOST) -d $(PRODUCT_STORAGE_DIR) -p orbe

.PHONY: run_full_tests
run_full_tests:
	$(WORKDIR)/sw_x/dist/igware.runtime/make_validated_links.sh -a save -u $(STORE_USER) -n $(STORE_HOST) -d $(PRODUCT_STORAGE_DIR) -s ccd_cloudnode -s CloudNodeClientSDK -s dxshell_cloudnode
	$(WORKDIR)/sw_x/tools/testharness/bin/testharness.py -c $(WORKDIR)/sw_x/tools/testharness/conf/runs/buildbot_tests.$(PRODUCT).full.$(LAB).run -o /tmp/testharness/output_$(PRODUCT)/$(BUILD_DATE) -b $(STORE_USER)@$(STORE_HOST):/$(FS_STORE_TEST_PATH)/$(BRANCH_NAME)/$(BUILD_DATE)_$(PRODUCT)_$(LAB) -k
	# since the tests have passed, create the links indicating the build has been validated
	$(WORKDIR)/sw_x/dist/igware.runtime/make_validated_links.sh -a link -u $(STORE_USER) -n $(STORE_HOST) -d $(PRODUCT_STORAGE_DIR) -p orbe

# --- this target should report the test results
.PHONY: report_test_results
report_test_results:
	# if the string "TEST RUN STATUS PASS" is not found in the summary output, then it's a fail
	cat /tmp/testharness/output_$(PRODUCT)/$(BUILD_DATE)/testharness_summary.out
	grep "TEST RUN STATUS PASS" /tmp/testharness/output_$(PRODUCT)/$(BUILD_DATE)/testharness_summary.out

# --- this target run once to setup a machine for build and/or test
.PHONY: build_setup
build_setup: allow_sudo_usage
	make -f $(WORKDIR)/sw_x/dist/igware.runtime/Makefile.cloudnode centos_update_repo
	make -f $(WORKDIR)/sw_x/dist/igware.runtime/Makefile.cloudnode install_common_pkgs
	make -f $(WORKDIR)/sw_x/dist/igware.runtime/Makefile.cloudnode centos_install_32bit_pkgs
	make -f $(WORKDIR)/sw_x/dist/igware.runtime/Makefile.cloudnode centos_install_java_1.6

# --- this target run once on all target machines to install packages required to run the tests
.PHONY: test_setup
test_setup: allow_sudo_usage
	make -f $(WORKDIR)/sw_x/dist/igware.runtime/Makefile.cloudnode centos_update_repo
	make -f $(WORKDIR)/sw_x/dist/igware.runtime/Makefile.cloudnode install_common_pkgs
	make -f $(WORKDIR)/sw_x/dist/igware.runtime/Makefile.cloudnode centos_install_32bit_pkgs
	# machine must be able to password-less SSH to itself
	cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
	# generate core file into a specific directory
	sudo mkdir -p /tmp/core
	sudo bash -c 'echo /tmp/core/core.%e.%p > /proc/sys/kernel/core_pattern'
	# Create usable temp directory for test results
	sudo mkdir -p /temp
	sudo chmod 777 /temp
	# manual step: make sure /tmp and /home/build are on the same filesystem
	echo "MANUAL STEP: Make sure /tmp and /home/build are on the same filesystem; move /tmp to /home/tmp if necessary"
